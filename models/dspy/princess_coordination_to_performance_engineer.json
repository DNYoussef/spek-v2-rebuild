{
  "delegate.predict": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "augmented": true,
        "phase": "performance-baseline",
        "context": "{\"application\": \"E-commerce platform\", \"metrics\": \"response time, throughput, resource usage\", \"goal\": \"establish performance baseline\"}",
        "reasoning": "For establishing a performance baseline of an e-commerce platform, we need a comprehensive performance analysis. The performance-engineer drone is best suited for this task as it specializes in performance measurement and analysis. The task will involve setting up monitoring, running load tests, and documenting baseline metrics across all critical paths and resources.",
        "drone_task": "{\n    \"drone_id\": \"performance-engineer\",\n    \"task_type\": \"establish-performance-baseline\",\n    \"description\": \"Create comprehensive performance baseline for e-commerce platform\",\n    \"payload\": {\n        \"metrics_collection\": [\n            \"response time (p50, p95, p99)\",\n            \"requests per second\",\n            \"CPU utilization\",\n            \"memory usage\",\n            \"disk I/O\",\n            \"network throughput\"\n        ],\n        \"test_scenarios\": [\n            \"normal load patterns\",\n            \"peak hour simulation\",\n            \"critical user journeys\",\n            \"API endpoint performance\"\n        ],\n        \"monitoring_setup\": {\n            \"tools\": [\"prometheus\", \"grafana\", \"jaeger\"],\n            \"retention_period\": \"30 days\",\n            \"alert_thresholds\": \"define initial thresholds\"\n        },\n        \"documentation\": {\n            \"baseline_report\": true,\n            \"performance_SLOs\": true,\n            \"resource_utilization\": true\n        }\n    },\n    \"acceptance_criteria\": [\n        \"Complete baseline metrics collected for all critical paths\",\n        \"Performance monitoring dashboard created\",\n        \"Baseline report generated with all key metrics\",\n        \"Initial SLOs defined based on measurements\",\n        \"Resource utilization patterns documented\"\n    ]\n}"
      },
      {
        "augmented": true,
        "phase": "load-testing",
        "context": "{\"event\": \"Black Friday sale\", \"expected_traffic\": \"10x normal load\", \"requirement\": \"validate system handles load\"}",
        "reasoning": "For this load testing phase, I'll assign the tester drone from the Princess-Quality group. This specialized drone has expertise in performance testing and can validate system behavior under heavy load. The task requires comprehensive load testing scenarios, monitoring, and clear acceptance criteria to ensure the system can handle 10x normal traffic during Black Friday.",
        "drone_task": "{\n    \"drone_id\": \"tester\",\n    \"task_type\": \"load-test-execution\",\n    \"description\": \"Execute comprehensive load tests to validate system performance for Black Friday sale\",\n    \"payload\": {\n        \"test_scenarios\": [\n            \"Gradual ramp-up to 10x normal load\",\n            \"Sustained peak load for 30 minutes\",\n            \"Spike tests simulating flash sales\",\n            \"Recovery testing after peak load\"\n        ],\n        \"metrics_to_monitor\": [\n            \"Response time\",\n            \"Error rate\",\n            \"Resource utilization\",\n            \"Database performance\",\n            \"Cache hit ratio\"\n        ],\n        \"test_duration\": \"4 hours\",\n        \"tools\": [\"JMeter\", \"Grafana\", \"Prometheus\"],\n        \"environment\": \"staging\"\n    },\n    \"acceptance_criteria\": [\n        \"System handles 10x normal load without errors\",\n        \"Response time p95 < 500ms under load\",\n        \"No resource exhaustion observed\",\n        \"Zero failed transactions\",\n        \"Recovery time < 1 minute after load decrease\"\n    ]\n}"
      },
      {
        "augmented": true,
        "phase": "database-optimization",
        "context": "{\"database\": \"PostgreSQL\", \"issue\": \"slow queries degrading performance\", \"goal\": \"optimize top 10 slowest queries\"}",
        "reasoning": "For database optimization tasks, I'll assign this to the performance-engineer drone who specializes in database tuning and query optimization. The task requires deep analysis of query patterns, execution plans, and implementation of various optimization techniques. The drone will need to:\n1. Analyze query performance using PostgreSQL tools\n2. Identify optimization opportunities through indexing, query rewriting\n3. Implement and validate improvements\n4. Ensure optimizations don't negatively impact other queries",
        "drone_task": "{\n    \"drone_id\": \"performance-engineer\",\n    \"task_type\": \"optimize-database-queries\",\n    \"description\": \"Analyze and optimize top 10 slowest PostgreSQL queries for improved performance\",\n    \"payload\": {\n        \"analysis_steps\": [\n            \"Enable and analyze pg_stat_statements\",\n            \"Collect EXPLAIN ANALYZE plans\",\n            \"Review index usage statistics\",\n            \"Identify table statistics issues\"\n        ],\n        \"optimization_techniques\": [\n            \"Create missing indexes\",\n            \"Rewrite inefficient queries\",\n            \"Update table statistics\",\n            \"Adjust query planner parameters\"\n        ],\n        \"tools\": [\n            \"pg_stat_statements\",\n            \"EXPLAIN ANALYZE\",\n            \"pgBadger\",\n            \"auto_explain\"\n        ],\n        \"target_metrics\": {\n            \"query_time_reduction\": \"80%\",\n            \"index_hit_ratio\": \">95%\"\n        }\n    },\n    \"acceptance_criteria\": [\n        \"Top 10 slow queries identified and documented\",\n        \"Query execution time reduced by 80%\",\n        \"No regression in other query performance\",\n        \"Index usage optimized with >95% hit ratio\",\n        \"Query plans documented before/after optimization\",\n        \"Performance improvements validated in production-like environment\"\n    ]\n}"
      },
      {
        "augmented": true,
        "phase": "caching-strategy",
        "context": "{\"application\": \"API with high read traffic\", \"current\": \"no caching\", \"goal\": \"implement multi-layer caching\"}",
        "reasoning": "For implementing a multi-layer caching strategy, I'll assign this to the performance-engineer drone who specializes in caching architectures and performance optimization. The task requires careful analysis of access patterns, data consistency requirements, and implementation of appropriate caching layers. The drone will need to consider in-memory caching, distributed caching, and CDN caching options while ensuring cache invalidation strategies are properly implemented.",
        "drone_task": "{\n    \"drone_id\": \"performance-engineer\",\n    \"task_type\": \"implement-caching-strategy\",\n    \"description\": \"Design and implement multi-layer caching solution for high-read API\",\n    \"payload\": {\n        \"analysis\": [\n            \"analyze read patterns and data access frequency\",\n            \"identify cacheable vs non-cacheable data\",\n            \"determine cache invalidation requirements\"\n        ],\n        \"caching_layers\": {\n            \"application\": \"in-memory caching (e.g., Caffeine)\",\n            \"distributed\": \"distributed cache (Redis/Memcached)\",\n            \"cdn\": \"CDN caching for static responses\"\n        },\n        \"implementation\": [\n            \"cache key design\",\n            \"TTL strategy\",\n            \"invalidation patterns\",\n            \"cache warming strategy\"\n        ],\n        \"monitoring\": [\n            \"cache hit rates\",\n            \"cache size metrics\",\n            \"invalidation events\"\n        ],\n        \"target\": \"achieve 80% cache hit rate\"\n    },\n    \"acceptance_criteria\": [\n        \"Multi-layer caching implemented and configured\",\n        \"Cache invalidation strategy documented and tested\",\n        \"Cache hit rate >= 80% for eligible requests\",\n        \"Response time improved by 50% for cached requests\",\n        \"Monitoring and alerts configured for cache performance\"\n    ]\n}"
      },
      {
        "augmented": true,
        "phase": "frontend-optimization",
        "context": "{\"application\": \"React SPA\", \"metrics\": \"Core Web Vitals failing\", \"goal\": \"optimize LCP, FID, CLS\"}",
        "reasoning": "For frontend optimization focusing on Core Web Vitals, I'll assign the performance-engineer drone. This task requires deep expertise in web performance optimization, React-specific optimizations, and modern browser capabilities. The task will be structured to address all three Core Web Vitals metrics (LCP, FID, CLS) with specific optimizations for each.",
        "drone_task": "{\n    \"drone_id\": \"performance-engineer\",\n    \"task_type\": \"optimize-frontend-performance\",\n    \"description\": \"Optimize React SPA Core Web Vitals metrics\",\n    \"payload\": {\n        \"metrics_focus\": {\n            \"LCP\": [\"lazy loading\", \"image optimization\", \"critical CSS\", \"preload key resources\"],\n            \"FID\": [\"code splitting\", \"minimize JS bundles\", \"defer non-critical JS\", \"optimize event handlers\"],\n            \"CLS\": [\"reserve space for dynamic content\", \"optimize font loading\", \"stabilize layouts\"]\n        },\n        \"optimizations\": {\n            \"build\": [\"tree shaking\", \"bundle analysis\", \"compression\"],\n            \"assets\": [\"next-gen image formats\", \"responsive images\", \"font optimization\"],\n            \"caching\": [\"service worker implementation\", \"cache strategies\"],\n            \"monitoring\": [\"setup RUM monitoring\", \"lighthouse CI integration\"]\n        },\n        \"targets\": {\n            \"LCP\": \"< 2.5s\",\n            \"FID\": \"< 100ms\",\n            \"CLS\": \"< 0.1\"\n        }\n    },\n    \"acceptance_criteria\": [\n        \"LCP improved to under 2.5s for 75th percentile\",\n        \"FID reduced to under 100ms for 95th percentile\",\n        \"CLS score maintained below 0.1\",\n        \"Bundle size reduced by minimum 30%\",\n        \"Performance monitoring dashboard implemented\",\n        \"No regression in functionality\"\n    ]\n}"
      },
      {
        "augmented": true,
        "phase": "api-optimization",
        "context": "{\"api\": \"REST API with GraphQL\", \"issue\": \"N+1 query problem, slow response times\", \"goal\": \"optimize API performance\"}",
        "reasoning": "For this API optimization task, I'll assign the performance-engineer drone due to their expertise in:\n1. API performance analysis and optimization\n2. GraphQL query optimization\n3. Database query patterns\n4. Response time improvements\n\nThe task will focus on solving the N+1 query problem through data loader implementation, query batching, and caching strategies. The performance-engineer drone has the necessary skills to analyze query patterns and implement optimizations while maintaining API functionality.",
        "drone_task": "{\n    \"drone_id\": \"performance-engineer\",\n    \"task_type\": \"optimize-api-performance\",\n    \"description\": \"Optimize REST API with GraphQL to resolve N+1 query problems and improve response times\",\n    \"payload\": {\n        \"analysis\": [\n            \"profile API endpoints\",\n            \"identify N+1 query patterns\",\n            \"analyze query execution plans\",\n            \"measure current response times\"\n        ],\n        \"optimizations\": [\n            \"implement DataLoader for batching\",\n            \"add field-level caching\",\n            \"optimize GraphQL resolvers\",\n            \"implement query batching\"\n        ],\n        \"monitoring\": {\n            \"metrics\": [\"response time\", \"query count\", \"cache hit ratio\"],\n            \"target\": \"reduce response time by 70%\"\n        }\n    },\n    \"acceptance_criteria\": [\n        \"N+1 queries eliminated through batching\",\n        \"Response times reduced by 70%\",\n        \"Cache implementation verified\",\n        \"No regression in API functionality\",\n        \"Performance metrics documented\"\n    ]\n}"
      },
      {
        "augmented": true,
        "phase": "memory-leak-investigation",
        "context": "{\"application\": \"Node.js microservice\", \"symptom\": \"memory usage growing over time, OOM crashes\", \"goal\": \"identify and fix memory leaks\"}",
        "reasoning": "For this memory leak investigation, I'll assign the debugger drone since it specializes in diagnostic work and complex issue investigation. The task requires deep analysis of memory patterns, heap snapshots, and potential leak sources in Node.js. The debugger drone has the necessary capabilities for memory profiling, heap analysis, and identifying memory retention patterns.\n\nThe task will be structured to follow a systematic debugging approach:\n1. Gather memory profiles and heap snapshots\n2. Analyze growth patterns and retained objects\n3. Identify leak sources\n4. Implement and verify fixes",
        "drone_task": "{\n    \"drone_id\": \"debugger\",\n    \"task_type\": \"memory-leak-analysis\",\n    \"description\": \"Investigate and fix memory leaks in Node.js microservice\",\n    \"payload\": {\n        \"analysis_steps\": [\n            \"Take heap snapshots at different intervals\",\n            \"Use Chrome DevTools Memory tab for analysis\",\n            \"Profile memory allocation patterns\",\n            \"Identify objects with growing retention\"\n        ],\n        \"investigation_areas\": [\n            \"Event listener cleanup\",\n            \"Cache management\",\n            \"Stream handling\",\n            \"Closure references\",\n            \"Timer cleanup\"\n        ],\n        \"tools\": [\n            \"node --inspect\",\n            \"heapdump module\",\n            \"Chrome DevTools\",\n            \"memory-leak-detector\"\n        ],\n        \"metrics\": {\n            \"baseline_memory\": \"capture initial usage\",\n            \"growth_rate\": \"measure increase over time\",\n            \"target_reduction\": \"95% memory growth elimination\"\n        }\n    },\n    \"acceptance_criteria\": [\n        \"Memory growth pattern documented with evidence\",\n        \"Root cause of leak(s) identified\",\n        \"Fix implemented and verified\",\n        \"Memory usage stable over 24-hour period\",\n        \"No OOM events under load test\",\n        \"Monitoring added for early detection\"\n    ]\n}"
      },
      {
        "augmented": true,
        "phase": "cdn-optimization",
        "context": "{\"assets\": \"images, videos, static files\", \"bandwidth\": \"high bandwidth costs\", \"goal\": \"optimize CDN usage and costs\"}",
        "reasoning": "For CDN optimization, we need a performance engineer drone who specializes in content delivery networks and asset optimization. The task requires analyzing current CDN usage, implementing best practices for asset delivery, and optimizing costs. The drone will need to work with various asset types and implement caching strategies while monitoring bandwidth usage and costs.",
        "drone_task": "{\n    \"drone_id\": \"performance-engineer\",\n    \"task_type\": \"optimize-cdn\",\n    \"description\": \"Optimize CDN configuration and asset delivery for reduced costs\",\n    \"payload\": {\n        \"analysis\": [\n            \"audit current CDN usage patterns\",\n            \"analyze asset sizes and types\",\n            \"review bandwidth consumption\",\n            \"identify optimization opportunities\"\n        ],\n        \"optimizations\": [\n            \"implement aggressive caching strategies\",\n            \"configure image compression and WebP conversion\",\n            \"set up video streaming optimization\",\n            \"enable Brotli compression\",\n            \"implement lazy loading\"\n        ],\n        \"monitoring\": {\n            \"metrics\": [\n                \"bandwidth usage\",\n                \"cache hit ratio\",\n                \"origin requests\",\n                \"CDN costs\"\n            ],\n            \"target\": \"reduce CDN costs by 40%\"\n        }\n    },\n    \"acceptance_criteria\": [\n        \"CDN configuration optimized for all asset types\",\n        \"Cache hit ratio increased to >90%\",\n        \"Bandwidth costs reduced by 40%\",\n        \"Asset loading time improved by 30%\",\n        \"Monitoring dashboard implemented\"\n    ]\n}"
      },
      {
        "augmented": true,
        "phase": "query-profiling",
        "context": "{\"database\": \"MongoDB\", \"collection\": \"1B documents\", \"issue\": \"slow aggregation queries\"}",
        "reasoning": "For MongoDB query profiling and optimization, we need a performance engineer drone with expertise in database optimization. The task requires deep analysis of aggregation pipelines, index usage, and query patterns. Given the large collection size (1B documents), careful profiling and systematic optimization approach is crucial. The task should focus on both immediate query optimization and establishing monitoring for future performance tracking.",
        "drone_task": "{\n    \"drone_id\": \"performance-engineer\",\n    \"task_type\": \"mongodb-query-optimization\",\n    \"description\": \"Profile and optimize slow MongoDB aggregation queries on large collection\",\n    \"payload\": {\n        \"analysis_steps\": [\n            \"Enable profiling with db.setProfilingLevel()\",\n            \"Analyze slow queries using explain() with allPlansExecution\",\n            \"Review index usage and coverage\",\n            \"Examine memory usage and disk spills\",\n            \"Analyze aggregation pipeline stages\"\n        ],\n        \"optimization_targets\": [\n            \"Index utilization\",\n            \"Pipeline stage optimization\",\n            \"Memory usage reduction\",\n            \"Shard key effectiveness\",\n            \"Query patterns\"\n        ],\n        \"tools\": [\n            \"MongoDB Compass\",\n            \"mongostat\",\n            \"mongotop\",\n            \"Database Profiler\"\n        ]\n    },\n    \"acceptance_criteria\": [\n        \"Slow queries identified and documented\",\n        \"Query execution plans analyzed\",\n        \"Index recommendations provided\",\n        \"Pipeline optimizations implemented\",\n        \"Performance improvement measured and documented\",\n        \"Monitoring system configured for ongoing profiling\"\n    ]\n}"
      },
      {
        "augmented": true,
        "phase": "microservices-latency",
        "context": "{\"architecture\": \"15 microservices with REST calls\", \"issue\": \"cascading latency, slow end-to-end response\", \"goal\": \"reduce inter-service latency\"}",
        "reasoning": "For this microservices latency optimization task, I'll assign the integration-engineer drone. This specialized drone has expertise in distributed systems, service communication patterns, and end-to-end performance optimization. The task requires analyzing service dependencies, communication patterns, and implementing various latency reduction strategies. The integration-engineer is best suited due to their knowledge of service mesh technologies, async patterns, and distributed tracing.",
        "drone_task": "{\n    \"drone_id\": \"integration-engineer\",\n    \"task_type\": \"optimize-microservices-latency\",\n    \"description\": \"Analyze and optimize inter-service communication latency across microservices architecture\",\n    \"payload\": {\n        \"analysis\": [\n            \"implement distributed tracing (Jaeger/Zipkin)\",\n            \"create service dependency graph\",\n            \"identify critical paths and bottlenecks\",\n            \"measure network latency between services\"\n        ],\n        \"optimizations\": [\n            \"implement circuit breakers\",\n            \"add response caching\",\n            \"optimize connection pooling\",\n            \"implement bulk operations\",\n            \"evaluate async communication patterns\"\n        ],\n        \"infrastructure\": [\n            \"service mesh implementation\",\n            \"load balancer optimization\",\n            \"network topology review\"\n        ],\n        \"target\": \"reduce end-to-end latency by 70%\"\n    },\n    \"acceptance_criteria\": [\n        \"distributed tracing implemented and analyzed\",\n        \"service mesh or equivalent optimization layer added\",\n        \"circuit breakers configured for failure isolation\",\n        \"end-to-end latency reduced by 70%\",\n        \"no single point of failure introduced\",\n        \"monitoring and alerts configured for latency spikes\"\n    ]\n}"
      }
    ],
    "signature": {
      "instructions": "Delegate task to drone agent with clear instructions.\n\nYou are a Princess agent coordinating your specialized drone hive.\nYour role is to take high-level workflow phases and convert them\ninto specific, actionable tasks for your drone agents.\n\nPrincess-Dev drones: coder, reviewer, debugger, integration-engineer\nPrincess-Quality drones: tester, nasa-enforcer, theater-detector, fsm-analyzer\nPrincess-Coordination drones: orchestrator, planner, cost-tracker\n\nEach drone task must have:\n- Specific drone agent assignment\n- Task type matching drone capabilities\n- Clear context from previous phases\n- Concrete deliverables\n- Quality gates/acceptance criteria\n\nFollow the 26 prompt engineering principles:\n- Clarity: Unambiguous instructions\n- Context: Include relevant phase results\n- Constraints: Respect drone capabilities\n- Structure: Output valid JSON format",
      "fields": [
        {
          "prefix": "Phase:",
          "description": "Development phase to execute (design, code, test, review, etc.)"
        },
        {
          "prefix": "Context:",
          "description": "Context and results from previous phases that this phase depends on"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "Delegation reasoning explaining drone selection and task structure"
        },
        {
          "prefix": "Drone Task:",
          "description": "Structured task for drone agent as JSON object. Must have: {'drone_id': str, 'task_type': str, 'description': str, 'payload': dict, 'acceptance_criteria': list[str]}"
        }
      ]
    },
    "lm": null
  },
  "metadata": {
    "dependency_versions": {
      "python": "3.12",
      "dspy": "3.0.3",
      "cloudpickle": "3.0"
    }
  }
}
