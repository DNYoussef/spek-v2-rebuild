{
  "delegate.predict": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "augmented": true,
        "phase": "deploy-infrastructure",
        "context": "{\"environment\": \"production\", \"cloud_provider\": \"AWS\", \"requirements\": \"Deploy microservices with auto-scaling and load balancing\", \"current_state\": \"staging environment validated\"}",
        "reasoning": "For production infrastructure deployment, we need the infrastructure-ops drone which specializes in cloud deployments and infrastructure automation. The task requires setting up a production-grade infrastructure with high availability and scalability features. Given the AWS environment and microservices architecture, we'll need comprehensive infrastructure-as-code deployment with proper security, monitoring, and auto-scaling configurations.",
        "drone_task": "{\n    \"drone_id\": \"infrastructure-ops\",\n    \"task_type\": \"infrastructure-deployment\",\n    \"description\": \"Deploy production AWS infrastructure for microservices architecture\",\n    \"payload\": {\n        \"components\": {\n            \"networking\": {\n                \"vpc\": \"multi-az\",\n                \"subnets\": [\"public\", \"private\", \"database\"],\n                \"nat_gateway\": \"highly available\"\n            },\n            \"compute\": {\n                \"eks_cluster\": \"1.25\",\n                \"node_groups\": \"auto-scaling\",\n                \"instance_types\": [\"t3.large\", \"m5.large\"]\n            },\n            \"load_balancing\": {\n                \"type\": \"application\",\n                \"ssl_termination\": true,\n                \"waf_integration\": true\n            },\n            \"monitoring\": {\n                \"cloudwatch\": true,\n                \"prometheus\": true,\n                \"grafana\": true\n            }\n        },\n        \"terraform_workspace\": \"production\",\n        \"region\": \"us-west-2\"\n    },\n    \"acceptance_criteria\": [\n        \"All infrastructure components deployed and healthy\",\n        \"Auto-scaling groups configured and tested\",\n        \"Load balancers properly routing traffic\",\n        \"Monitoring and alerting operational\",\n        \"Security groups and IAM roles properly configured\",\n        \"High availability verified across availability zones\",\n        \"Infrastructure documentation updated\"\n    ]\n}"
      },
      {
        "augmented": true,
        "phase": "containerize",
        "context": "{\"application\": \"Python FastAPI microservice\", \"requirements\": \"Multi-stage build, minimal image size\", \"registry\": \"AWS ECR\"}",
        "reasoning": "For containerizing a Python FastAPI microservice with optimization requirements, I'll delegate to the integration-engineer drone. This drone specializes in container builds, optimization, and registry management. The task requires expertise in multi-stage Docker builds to minimize image size while maintaining application functionality. The integration-engineer will handle Dockerfile creation, build optimization, and image pushing to AWS ECR.",
        "drone_task": "{\n    \"drone_id\": \"integration-engineer\",\n    \"task_type\": \"containerization\",\n    \"description\": \"Create optimized Docker container for Python FastAPI microservice using multi-stage build\",\n    \"payload\": {\n        \"dockerfile_specs\": {\n            \"base_image\": \"python:3.11-slim\",\n            \"build_stages\": [\n                \"dependencies\",\n                \"runtime\"\n            ],\n            \"optimization_targets\": [\n                \"minimal dependencies\",\n                \"layer caching\",\n                \"security scanning\"\n            ]\n        },\n        \"build_args\": {\n            \"PORT\": \"8000\",\n            \"ENVIRONMENT\": \"production\"\n        },\n        \"registry_config\": {\n            \"type\": \"AWS ECR\",\n            \"region\": \"us-west-2\",\n            \"tags\": [\"latest\", \"BUILD_ID\"]\n        }\n    },\n    \"acceptance_criteria\": [\n        \"Image size under 500MB\",\n        \"Multi-stage build implemented\",\n        \"All tests pass in container\",\n        \"Successfully pushed to ECR\",\n        \"No high/critical vulnerabilities\",\n        \"Container starts in under 3 seconds\"\n    ]\n}"
      },
      {
        "augmented": true,
        "phase": "setup-cicd",
        "context": "{\"platform\": \"GitHub Actions\", \"workflow\": \"Build, test, deploy on merge to main\", \"environments\": [\"staging\", \"production\"]}",
        "reasoning": "For setting up a CI/CD pipeline with GitHub Actions, I'll delegate to the integration-engineer drone. This drone specializes in configuring automated workflows and deployment pipelines. The task requires expertise in GitHub Actions, environment management, and deployment strategies. The integration-engineer will ensure proper setup of build, test, and deployment stages with appropriate security controls and quality gates.",
        "drone_task": "{\n    \"drone_id\": \"integration-engineer\",\n    \"task_type\": \"setup-cicd-pipeline\",\n    \"description\": \"Configure GitHub Actions workflow for automated build, test, and deployment pipeline\",\n    \"payload\": {\n        \"workflow_file\": \".github/workflows/main.yml\",\n        \"stages\": [\n            \"build\",\n            \"unit-test\",\n            \"integration-test\",\n            \"security-scan\",\n            \"deploy-staging\",\n            \"deploy-production\"\n        ],\n        \"environment_config\": {\n            \"staging\": {\n                \"auto_deploy\": true,\n                \"approval\": false\n            },\n            \"production\": {\n                \"auto_deploy\": false,\n                \"approval\": true\n            }\n        },\n        \"security_measures\": [\n            \"secrets management\",\n            \"RBAC configuration\",\n            \"environment protection rules\"\n        ]\n    },\n    \"acceptance_criteria\": [\n        \"Workflow successfully triggers on merge to main branch\",\n        \"All stages execute in correct order\",\n        \"Environment-specific configurations are properly isolated\",\n        \"Secrets are securely managed\",\n        \"Production deployments require approval\",\n        \"Pipeline status is visible in GitHub UI\",\n        \"Failed builds notify relevant team members\"\n    ]\n}"
      },
      {
        "augmented": true,
        "phase": "infrastructure-as-code",
        "context": "{\"tool\": \"Terraform\", \"cloud\": \"GCP\", \"resources\": \"VPC, GKE cluster, Cloud SQL, Redis\"}",
        "reasoning": "For infrastructure-as-code implementation using Terraform on GCP, I'll assign this to the infrastructure-ops drone. This drone specializes in infrastructure automation and cloud platform configurations. The task requires expertise in Terraform, GCP services, and infrastructure best practices. The task will be structured to ensure proper resource creation, state management, and validation of the infrastructure deployment.",
        "drone_task": "{\n    \"drone_id\": \"infrastructure-ops\",\n    \"task_type\": \"terraform-implementation\",\n    \"description\": \"Create Terraform configurations for GCP infrastructure deployment\",\n    \"payload\": {\n        \"resources\": {\n            \"vpc\": {\n                \"network\": \"custom mode VPC\",\n                \"subnets\": [\"gke-subnet\", \"db-subnet\"],\n                \"firewall\": \"least privilege rules\"\n            },\n            \"gke\": {\n                \"version\": \"latest stable\",\n                \"node_pools\": [\"system\", \"application\"],\n                \"private_cluster\": true\n            },\n            \"cloud_sql\": {\n                \"engine\": \"PostgreSQL\",\n                \"ha\": true,\n                \"backup\": \"enabled\"\n            },\n            \"redis\": {\n                \"tier\": \"standard\",\n                \"memory_size\": \"5GB\"\n            }\n        },\n        \"state_management\": {\n            \"backend\": \"GCS bucket\",\n            \"state_locking\": true\n        },\n        \"modules\": {\n            \"structure\": \"modular design\",\n            \"reusability\": \"parameterized\"\n        }\n    },\n    \"acceptance_criteria\": [\n        \"All Terraform configurations validate successfully\",\n        \"Resources can be created and destroyed cleanly\",\n        \"State file properly managed in remote backend\",\n        \"All resources follow security best practices\",\n        \"Documentation includes usage instructions\",\n        \"Variables properly defined with descriptions\",\n        \"Output values configured for resource attributes\"\n    ]\n}"
      },
      {
        "augmented": true,
        "phase": "monitoring-setup",
        "context": "{\"stack\": \"Prometheus + Grafana + Loki\", \"cluster\": \"Kubernetes on Azure AKS\", \"metrics\": \"Application and infrastructure metrics\"}",
        "reasoning": "For setting up comprehensive monitoring on AKS, I'll delegate to the infrastructure-ops drone which specializes in observability implementations. The task requires configuring multiple monitoring components (Prometheus, Grafana, Loki) with proper integration into AKS. The drone will need to handle Helm deployments, configure data sources, and ensure proper metric collection and visualization. Success criteria will focus on complete visibility across the stack.",
        "drone_task": "{\n    \"drone_id\": \"infrastructure-ops\",\n    \"task_type\": \"setup-monitoring\",\n    \"description\": \"Deploy and configure complete monitoring stack on AKS cluster\",\n    \"payload\": {\n        \"components\": {\n            \"prometheus\": {\n                \"version\": \"latest\",\n                \"retention\": \"15d\",\n                \"storage\": \"100Gi\",\n                \"scrape_interval\": \"30s\"\n            },\n            \"grafana\": {\n                \"version\": \"latest\",\n                \"persistence\": true,\n                \"plugins\": [\"azure-monitor\", \"kubernetes-app\"],\n                \"dashboards\": [\"node-exporter\", \"kubernetes-cluster\", \"application-metrics\"]\n            },\n            \"loki\": {\n                \"version\": \"latest\",\n                \"retention\": \"7d\",\n                \"storage\": \"50Gi\"\n            }\n        },\n        \"configurations\": {\n            \"service_discovery\": \"enabled\",\n            \"alerting\": \"prometheus-alertmanager\",\n            \"authentication\": \"Azure AD integration\",\n            \"backup\": \"daily dashboard exports\"\n        }\n    },\n    \"acceptance_criteria\": [\n        \"All components deployed and healthy in AKS\",\n        \"Metrics successfully collected from all nodes and pods\",\n        \"Grafana dashboards showing live data\",\n        \"Log aggregation working in Loki\",\n        \"Alerting rules configured and tested\",\n        \"Authentication working with Azure AD\",\n        \"Backup system verified\"\n    ]\n}"
      },
      {
        "augmented": true,
        "phase": "database-migration",
        "context": "{\"database\": \"PostgreSQL 12 to 14 upgrade\", \"size\": \"500GB\", \"downtime_window\": \"2 hours maintenance window\"}",
        "reasoning": "For a critical database migration task, I'll assign this to the infrastructure-ops drone due to:\n1. Complex database operation requiring infrastructure expertise\n2. Need for careful planning and execution to minimize downtime\n3. Requirement for thorough testing and rollback procedures\n4. Infrastructure-level access and coordination needed\n\nThe task will be structured to ensure:\n- Proper backup and verification steps\n- Minimal downtime within maintenance window\n- Data integrity validation\n- Performance testing post-migration",
        "drone_task": "{\n    \"drone_id\": \"infrastructure-ops\",\n    \"task_type\": \"database-migration\",\n    \"description\": \"Perform PostgreSQL upgrade from version 12 to 14 with minimal downtime\",\n    \"payload\": {\n        \"pre_migration\": {\n            \"backup\": \"Full backup with verification\",\n            \"disk_space\": \"Ensure 2x current size available\",\n            \"test_run\": \"Practice migration in staging\"\n        },\n        \"migration_steps\": [\n            \"Stop application writes\",\n            \"Create final backup\",\n            \"Perform pg_upgrade with --link mode\",\n            \"Validate data integrity\",\n            \"Update connection strings\",\n            \"Resume application\"\n        ],\n        \"monitoring\": {\n            \"metrics\": [\"query performance\", \"connection count\", \"replication lag\"],\n            \"alerts\": [\"migration progress\", \"errors\", \"completion\"]\n        }\n    },\n    \"acceptance_criteria\": [\n        \"Zero data loss confirmed\",\n        \"All tables and indexes verified\",\n        \"Queries perform same or better than before\",\n        \"Completed within 2-hour window\",\n        \"Applications successfully reconnected\",\n        \"Backup retention policy maintained\",\n        \"Rollback plan verified\"\n    ]\n}"
      },
      {
        "augmented": true,
        "phase": "scaling-configuration",
        "context": "{\"application\": \"E-commerce platform\", \"traffic_pattern\": \"Peak 10x during sales events\", \"current\": \"3 replicas, manual scaling\"}",
        "reasoning": "For this scaling configuration task, I'll delegate to the infrastructure-ops drone since it specializes in infrastructure and scaling operations. The task requires implementing both horizontal pod autoscaling (HPA) and vertical pod autoscaling (VPA) to handle the 10x traffic spikes during sales events. The drone will need to configure metrics-based autoscaling, set appropriate thresholds, and ensure proper monitoring is in place. Quality gates will verify scaling effectiveness under load.",
        "drone_task": "{\n    \"drone_id\": \"infrastructure-ops\",\n    \"task_type\": \"configure-autoscaling\",\n    \"description\": \"Implement comprehensive autoscaling solution for e-commerce platform to handle 10x traffic spikes\",\n    \"payload\": {\n        \"horizontal_scaling\": {\n            \"min_replicas\": 3,\n            \"max_replicas\": 30,\n            \"target_cpu_utilization\": 70,\n            \"target_memory_utilization\": 80,\n            \"custom_metrics\": [\"requests-per-second\", \"queue-length\"]\n        },\n        \"vertical_scaling\": {\n            \"enable_vpa\": true,\n            \"resource_limits\": {\n                \"cpu_range\": \"0.5-4 cores\",\n                \"memory_range\": \"1Gi-8Gi\"\n            }\n        },\n        \"cluster_autoscaler\": {\n            \"enabled\": true,\n            \"min_nodes\": 3,\n            \"max_nodes\": 15\n        },\n        \"monitoring\": {\n            \"metrics\": [\"pod_cpu\", \"pod_memory\", \"http_requests\", \"response_time\"],\n            \"alerts\": [\"scaling_events\", \"resource_saturation\"]\n        }\n    },\n    \"acceptance_criteria\": [\n        \"HPA successfully scales pods based on CPU/memory metrics\",\n        \"VPA adjusts resource requests/limits appropriately\",\n        \"Cluster autoscaler adds/removes nodes as needed\",\n        \"System handles simulated 10x traffic increase\",\n        \"No service disruption during scaling events\",\n        \"Scaling metrics and alerts properly configured\",\n        \"Cost optimization maintained during quiet periods\"\n    ]\n}"
      },
      {
        "augmented": true,
        "phase": "disaster-recovery",
        "context": "{\"requirement\": \"RPO 1 hour, RTO 4 hours\", \"infrastructure\": \"Multi-region AWS deployment\", \"data\": \"PostgreSQL + S3 assets\"}",
        "reasoning": "For this disaster recovery implementation, I'll delegate to the infrastructure-ops drone due to the complex nature of multi-region AWS setup and database replication requirements. The task requires expertise in AWS services, PostgreSQL replication, and automated failover procedures to meet the strict RPO/RTO requirements. The drone will need to implement cross-region replication, automated backups, and failover testing procedures.",
        "drone_task": "{\n    \"drone_id\": \"infrastructure-ops\",\n    \"task_type\": \"implement-dr-strategy\",\n    \"description\": \"Implement cross-region disaster recovery solution meeting RPO 1hr and RTO 4hr requirements\",\n    \"payload\": {\n        \"primary_region\": \"us-east-1\",\n        \"dr_region\": \"us-west-2\",\n        \"components\": {\n            \"database\": {\n                \"type\": \"PostgreSQL\",\n                \"replication\": \"streaming\",\n                \"backup_schedule\": \"hourly\",\n                \"snapshot_retention\": \"7 days\"\n            },\n            \"storage\": {\n                \"type\": \"S3\",\n                \"replication\": \"cross-region\",\n                \"versioning\": \"enabled\"\n            },\n            \"monitoring\": {\n                \"cloudwatch_alarms\": true,\n                \"health_checks\": \"1-minute intervals\"\n            }\n        },\n        \"automation\": {\n            \"failover_script\": \"automated\",\n            \"backup_verification\": \"daily\",\n            \"dr_testing\": \"monthly\"\n        }\n    },\n    \"acceptance_criteria\": [\n        \"Cross-region replication configured and verified\",\n        \"RPO of 1 hour demonstrated through backup testing\",\n        \"RTO of 4 hours validated through failover drills\",\n        \"Automated failover procedures documented and tested\",\n        \"Monitoring and alerting system operational\",\n        \"DR runbook created and validated\"\n    ]\n}"
      },
      {
        "augmented": true,
        "phase": "security-hardening",
        "context": "{\"cluster\": \"Production Kubernetes\", \"compliance\": \"SOC2, HIPAA requirements\", \"threat_model\": \"External and internal threats\"}",
        "reasoning": "For security hardening of a production Kubernetes cluster with strict compliance requirements, I'll delegate to the nasa-enforcer drone from the Princess-Quality group. This drone specializes in security compliance and validation, making it ideal for implementing comprehensive security measures. The task will be structured to address both infrastructure and application-level security controls, with specific acceptance criteria aligned with SOC2 and HIPAA requirements.",
        "drone_task": "{\n    \"drone_id\": \"nasa-enforcer\",\n    \"task_type\": \"security-hardening\",\n    \"description\": \"Implement comprehensive security controls for Kubernetes cluster following SOC2 and HIPAA requirements\",\n    \"payload\": {\n        \"security_controls\": {\n            \"network_policies\": \"default-deny with explicit allows\",\n            \"pod_security\": {\n                \"policies\": \"restricted\",\n                \"seccomp\": \"runtime/default\",\n                \"privileged\": false\n            },\n            \"rbac\": {\n                \"service_accounts\": \"least-privilege\",\n                \"namespace_isolation\": true\n            },\n            \"encryption\": {\n                \"secrets\": \"sealed-secrets\",\n                \"etcd\": \"encryption-at-rest\"\n            },\n            \"monitoring\": {\n                \"audit_logging\": true,\n                \"falco\": \"runtime security\",\n                \"prometheus_alerts\": \"security events\"\n            }\n        },\n        \"compliance_requirements\": {\n            \"soc2\": [\"access_control\", \"system_boundaries\", \"encryption\"],\n            \"hipaa\": [\"data_protection\", \"access_logging\", \"authentication\"]\n        }\n    },\n    \"acceptance_criteria\": [\n        \"All pods running with non-root users\",\n        \"Network policies enforced in all namespaces\",\n        \"RBAC policies follow least-privilege principle\",\n        \"Audit logging enabled and verified\",\n        \"Security scanning integrated in CI/CD\",\n        \"Compliance requirements documented and validated\",\n        \"Incident response procedures tested\",\n        \"Security monitoring dashboards operational\"\n    ]\n}"
      },
      {
        "augmented": true,
        "phase": "service-mesh",
        "context": "{\"requirement\": \"Mutual TLS, traffic management, observability\", \"cluster\": \"Kubernetes with 15 microservices\", \"mesh\": \"Istio\"}",
        "reasoning": "For implementing a service mesh with Istio across 15 microservices, I'll delegate to the infrastructure-ops drone. This requires expertise in Kubernetes, networking, security, and observability. The task needs careful orchestration to avoid service disruption and ensure all security/monitoring features are properly configured. The drone will need to implement mTLS, configure traffic policies, and set up observability tools while maintaining high availability.",
        "drone_task": "{\n    \"drone_id\": \"infrastructure-ops\",\n    \"task_type\": \"implement-service-mesh\",\n    \"description\": \"Deploy and configure Istio service mesh with full security and observability features\",\n    \"payload\": {\n        \"istio_components\": {\n            \"version\": \"1.18\",\n            \"core\": [\"istiod\", \"ingress-gateway\", \"egress-gateway\"],\n            \"addons\": [\"kiali\", \"jaeger\", \"prometheus\", \"grafana\"]\n        },\n        \"security\": {\n            \"mtls\": \"STRICT\",\n            \"authorization\": \"RBAC policies\",\n            \"certificates\": \"auto-rotation enabled\"\n        },\n        \"traffic_management\": {\n            \"routing\": \"weighted routing rules\",\n            \"resilience\": [\"circuit breaking\", \"retry policies\", \"timeout configs\"],\n            \"canary\": \"support progressive delivery\"\n        },\n        \"observability\": {\n            \"metrics\": \"Prometheus scraping\",\n            \"tracing\": \"Jaeger with 1% sampling\",\n            \"logging\": \"structured JSON format\",\n            \"dashboards\": \"Kiali service topology\"\n        }\n    },\n    \"acceptance_criteria\": [\n        \"All services enrolled in mesh with sidecar injection\",\n        \"mTLS verified between all services\",\n        \"Traffic routing policies applied and tested\",\n        \"Observability stack operational with data flow\",\n        \"Zero downtime during implementation\",\n        \"Performance impact < 10ms latency\",\n        \"Dashboard showing service topology\",\n        \"Alert rules configured for mesh health\"\n    ]\n}"
      }
    ],
    "signature": {
      "instructions": "Delegate task to drone agent with clear instructions.\n\nYou are a Princess agent coordinating your specialized drone hive.\nYour role is to take high-level workflow phases and convert them\ninto specific, actionable tasks for your drone agents.\n\nPrincess-Dev drones: coder, reviewer, debugger, integration-engineer\nPrincess-Quality drones: tester, nasa-enforcer, theater-detector, fsm-analyzer\nPrincess-Coordination drones: orchestrator, planner, cost-tracker\n\nEach drone task must have:\n- Specific drone agent assignment\n- Task type matching drone capabilities\n- Clear context from previous phases\n- Concrete deliverables\n- Quality gates/acceptance criteria\n\nFollow the 26 prompt engineering principles:\n- Clarity: Unambiguous instructions\n- Context: Include relevant phase results\n- Constraints: Respect drone capabilities\n- Structure: Output valid JSON format",
      "fields": [
        {
          "prefix": "Phase:",
          "description": "Development phase to execute (design, code, test, review, etc.)"
        },
        {
          "prefix": "Context:",
          "description": "Context and results from previous phases that this phase depends on"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "Delegation reasoning explaining drone selection and task structure"
        },
        {
          "prefix": "Drone Task:",
          "description": "Structured task for drone agent as JSON object. Must have: {'drone_id': str, 'task_type': str, 'description': str, 'payload': dict, 'acceptance_criteria': list[str]}"
        }
      ]
    },
    "lm": null
  },
  "metadata": {
    "dependency_versions": {
      "python": "3.12",
      "dspy": "3.0.3",
      "cloudpickle": "3.0"
    }
  }
}
